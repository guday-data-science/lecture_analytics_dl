{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------\n",
    "*Draft*\n",
    "v4. 30-Nov-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 과정 - Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP in `tensorflow`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tensorflow`의 작동원리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`텐서플로` : 머신러닝의 심층 신경망 구현을 위한 소프트웨어 프레임워크**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/mlp_tf/image_tensor_new.png\" width=550 height=550 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/mlp_tf/mnist.png\" width=600 height=600 align=\"center\">\n",
    "<font color=\"grey\"><div style=\"text-align: right\"> [참조] derindelimavi.blogspot.com/2015/04/mnist-el-yazs-rakam-veri-seti.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  `텐서` \n",
    ": 텐서플로우에서 딥러닝의 데이터를 표현하는 방법 Tensor object\n",
    "\n",
    "* 주로 행렬로 그래프에 전달됨\n",
    "* 스칼라, 벡터, 행렬, 다차원 배열 등 다양한 단위가 가능함\n",
    "* [참고] 텐서 tensor : n 차원 배열을 가리키는 수학 용어 (텐서플로 이름의 유래)\n",
    "    * 1 x 1 텐서 = 스칼라\n",
    "    * 1 x n 텐서 = 벡터\n",
    "    * n x n 텐서 = 행렬\n",
    "    * n x n x n 텐서 = 3차원 배열 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/mlp_tf/structure.png\" width=650 height=650 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서 배열과 형태\n",
    "* **`get_shape()`** 메서드는 텐서의 형태를 정수의 튜플로 반환\n",
    "    * 튜플의 원소의 개수 : 텐서의 차원수 \n",
    "    * 튜플의 각 정수 : 해당 차원의 배열 항목의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tf/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/envs/tf/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([1, 2, 3])\n",
    "\n",
    "print(a.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.constant([[1, 2, 3], \n",
    "                 [4, 5, 6]]) \n",
    "\n",
    "print(b.get_shape()) # 차원은 2개, # 각 차원의 항목의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant([[1],\n",
    "                 [2],\n",
    "                 [3]])\n",
    "\n",
    "print(c.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서 타입 \n",
    "<img src=\"images/mlp_tf/tensor_type_new.png\" width=600 height=600 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  **`variable` : 변수. 연산 과정에서 업데이트 되는 값**\n",
    "    * 학습과정에서 조정되는 모델의 매개변수(가중치, 편향 등)를 표현하는 방법    \n",
    "    - y = `W`x + `b` + 2\n",
    "    * ** tf.Variable( initial_value ) ** : 초기값과 초기화 작업이 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([3, 2])) # 변수 생성 (초기값 지정)\n",
    "\n",
    "\n",
    "init_op = tf.global_variables_initializer() # 초기화\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)       # 초기화 실행\n",
    "    print(sess.run(W))      # 변수 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **`constant` : 고정된 상수값**\n",
    "    * y = Wx + b + `2`\n",
    "    * **tf.constant( value**, dtype, shape, name **)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = tf.constant(\"Hello\") # 고정값 생성\n",
    "c2 = tf.constant(2) \n",
    "c3 = tf.constant(-1.0, shape=[2, 3]) # 고정값 생성 & shape 지정\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c1)); print(sess.run(c2)); print(sess.run(c3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **`placeholder` : 빈 변수. 나중에 입력값을 공급받기 위한 텐서플로 구조**\n",
    "    * 그래프가 실행되는 시점에 플레이스홀더에 입력 데이터가 들어감  \n",
    "    - `y` = W`x` + b + 2\n",
    "    * **tf.placeholder( shape, dtype**, name )\n",
    "        - 입력될 데이터의 shape, dtype 정의\n",
    "        - shape이 None이면 모든 크기의 데이터를 받을 수 있다는 의미\n",
    "        - 그래프 실행 시점에 feed_dict 인수를 사용해 딕셔너리 형태로 입력 값을 받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [[1,2]] # 입력 데이터\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape= [None, 2]) # 플레이스홀더 생성\n",
    "W = 2\n",
    "node = tf.add(X, W) # 덧셈 연산\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(node, feed_dict={X: input_data})) # 실행시점에 입력 데이터가 들어감"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph와 Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/mlp_tf/tensor_mechanism.png\" width=700 height=700 align=\"center\">\n",
    "<font color=\"grey\"><div style=\"text-align: right\"> [참조] www.mathwarehouse.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`Graph` : 알고리즘을 구성하는 연산의 상호작용(흐름) 그래프**\n",
    "    - **노드** : 하나의 연산\n",
    "    - **엣지** : 연산에 의해 소비되거나 생성되는 데이터\n",
    "    - **tf.< operator >** 메소드를 사용하여 연산 그래프 구성\n",
    "        - tf.add(), matmul(), multiply(), subtract(), divide() 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a = tf.constant([[1, 2, 3],\n",
    "                        [4, 5, 6]])\n",
    "\n",
    "tensor_b = tf.constant([[2],\n",
    "                        [3],\n",
    "                        [2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_c = tf.matmul(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/mlp_tf/graph_concept_new.png\" width=500 height=500 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`Session` : 정의한 연산 그래프 실행**\n",
    "    * 세션은 그래프를 CPU 또는 GPU와 같은 하드웨어에 올려주고 실행하도록 하는 텐서플로 API\n",
    "    * **세션 생성**\n",
    "        - tf.Session( )\n",
    "    * **세션 실행**\n",
    "        - Session 객체의 .run( ) 메서드에 출력하려는 노드값 입력\n",
    "        - 메서드가 호출되면, 출력하려는 노드에서 시작해 역방향으로 의존관계에 따라 필요한 노드들만 연산 수행\n",
    "        - tf.Session.run(accuracy)\n",
    "    * **세션 종료**\n",
    "        - Session 객체의 .close( ) 명령을 사용해 세션을 종료\n",
    "        - 세션에서 사용하는 자원을 해제하는 습관 가지는 것이 좋음\n",
    "    * **자동 세션 종료**\n",
    "        - 파이썬의 with 구문을 사용하여 세션을 열면 모든 연산이 완료된 후 자동으로 세션이 닫힘\n",
    "        - with tf.Session( ) as sess :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    edge_d = sess.run(node_c)\n",
    "    \n",
    "print(edge_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`name` : 텐서 객체마다 가지는 고유의 이름**\n",
    "    - 하나의 그래프 내의 객체는 동일한 이름을 가질 수 없음\n",
    "    - 변수의 이름과는 다름\n",
    "    -  .name 속성을 사용\n",
    "    - name 입력 시에도 값 출력 가능<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1:0\n",
      "v2:0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "v1 = tf.Variable(1., name='v1')\n",
    "v2 = tf.Variable(2., name='v2')\n",
    "\n",
    "print(v1.name)\n",
    "print(v2.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run(\"v1:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1_1:0\n",
      "v2_1:0\n"
     ]
    }
   ],
   "source": [
    "v1 = tf.Variable(1., name='v1')\n",
    "v2 = tf.Variable(2., name='v2')\n",
    "\n",
    "print(v1.name)\n",
    "print(v2.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`name_scope` : 크고 복잡한 그래프인 경우, 쉽게 관리하기 위해, 노드를 그룹화**\n",
    "    - 각 tensor마다 고유의 name이 있기 때문에, 좀 더 구조적인 관리를 위해 name_scope 사용\n",
    "    - 그래프의 구조를 시각화 할 때 유용\n",
    "    - with tf.name_scope(“접두사”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scope1/v1:0\n",
      "scope1/v2:0\n",
      "v3:0\n",
      "v4:0\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"scope1\"):\n",
    "    v1 = tf.Variable(1., name='v1')\n",
    "    v2 = tf.Variable(2., name='v2')\n",
    "    v3 = tf.get_variable(\"v3\",1,initializer=tf.constant_initializer(3.))\n",
    "    v4 = tf.get_variable(\"v4\",1,initializer=tf.constant_initializer(4.))\n",
    "\n",
    "print(v1.name)\n",
    "print(v2.name)\n",
    "print(v3.name)\n",
    "print(v4.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`variable scope` : name scope처럼 기존에 존재하는 변수를 신규생성하지 않고 name scope으로 관리 가능**\n",
    "    - tf.get_variable()은 name_scope 영향을 받지 않고 그래프에 기존 이름이 있으면 새로운 이름을 생성\n",
    "    - tf.get_variable()도 name_sceop 영향을 받을 수 있도록 도와주는 것이 variable scope \n",
    "    - 기존 변수를 그대로 가지고 올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scope2/v1:0\n",
      "scope2/v2:0\n",
      "scope2/v3:0\n",
      "scope2/v4:0\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"scope2\"):\n",
    "    v1 = tf.Variable(1., name='v1')\n",
    "    v2 = tf.Variable(2., name='v2')\n",
    "    v3 = tf.get_variable(\"v3\",1,initializer=tf.constant_initializer(3.))\n",
    "    v4 = tf.get_variable(\"v4\",1,initializer=tf.constant_initializer(4.))\n",
    "\n",
    "print(v1.name)\n",
    "print(v2.name)\n",
    "print(v3.name)\n",
    "print(v4.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.]\n",
      "[3.]\n",
      "scope2/v3:0\n",
      "scope2/v3:0\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"scope2\", reuse=True): # 기존 생성된 변수가 없으면\n",
    "    v3_ = tf.get_variable(\"v3\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run(v3_))\n",
    "    print(sess.run(v3))\n",
    "    \n",
    "    print(v3_.name)\n",
    "    print(v3.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensors_flowing](images/mlp_tf/tensors_flowing.gif \"tensors_flowing\")\n",
    "<font color=\"grey\"><div style=\"text-align: right\"> [참조] www.tensorflow.org/guide/graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [실습] MLP 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/mlp_tf/mlp_concept.png\" width=700 height=800 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 랜덤값 생성\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "# 훈련 데이터 로딩\n",
    "train_x_mlp = np.load('data/train_x_mlp.npy')\n",
    "train_y_mlp = np.load('data/train_y_mlp.npy')\n",
    "\n",
    "# 테스트 데이터 로딩\n",
    "test_x_mlp = np.load('data/test_x_mlp.npy')\n",
    "test_y_mlp = np.load('data/test_y_mlp.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 확인\n",
    "train_x_mlp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 형태 확인\n",
    "train_x_mlp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_mlp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_mlp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 확인\n",
    "test_x_mlp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인풋 데이터\n",
    "* **입력값이 들어갈 구조 생성**\n",
    "    - **`tf.placeholder( 입력받을 데이터의 dtype, shape=[ 샘플 데이터 개수, 데이터의 원소 개수 ])`**\n",
    "        - shape의 샘플 데이터 개수를 None으로 지정하면 모든 크기의 데이터를 받을 수 있다는 뜻\n",
    "        - 그래프 실행 시점에 session.run() 메서드에 입력 데이터값 전달하면 플레이스 홀더에 입력값이 들어감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정\n",
    "input_dim  = train_x_mlp.shape[1]\n",
    "output_dim = train_y_mlp.shape[1]\n",
    "\n",
    "layer1_unit_num = 4\n",
    "layer2_unit_num = output_dim # 2\n",
    "\n",
    "\n",
    "# 데이터 입력 (플레이스홀더) \n",
    "X = tf.placeholder(tf.float32, [None, input_dim]) # 3\n",
    "Y_true = tf.placeholder(tf.float32, [None, output_dim]) # 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 레이어 구성\n",
    "\n",
    "* **가중치 생성**\n",
    "    - **` tf.Variable(초기값 설정)`**\n",
    "        - tf.random_normal() : 랜덤값으로 초기화 \n",
    "        - tf.zeros() : 0값으로 초기화\n",
    "    - **` tf.Variable(tf.random_normal(shape= [ 입력 데이터 원소 개수 , 레이어의 원소 개수 ])`**\n",
    "        - shape의 행은 입력 데이터의 원소 개수와 같아야 하고, 열은 생성하고 싶은 만큼 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"blue\"> 레이어 그림 수정 필요\n",
    "<img src=\"images/mlp_tf/mlp_concept.png\" width=700 height=800 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **레이어 생성**\n",
    "    -  Layer1 =  **` tf.sigmoid( tf.matmul(입력데이터, 가중치1) + 편향1 )`**\n",
    "    -  Layer2 =  **` tf.sigmoid( tf.matmul(Layer1 , 가중치2) + 편향2 )`**\n",
    "    -  예측값 = ** Layer2 **\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이어 구성\n",
    "W1 = tf.Variable(tf.random_normal(shape=(input_dim, layer1_unit_num)))\n",
    "b1 = tf.Variable(tf.random_normal(shape=(layer1_unit_num,)))\n",
    "Layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal(shape=(layer1_unit_num, layer2_unit_num)))\n",
    "b2 = tf.Variable(tf.random_normal(shape=(layer2_unit_num,)))\n",
    "Layer2 = tf.sigmoid(tf.matmul(Layer1, W2) + b2)\n",
    "\n",
    "\n",
    "# 결과값 확인\n",
    "Y_pred = Layer2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적화 (학습)\n",
    "\n",
    "- **실제 결과와 함수에서 예측한 결과의 차이를 확인 (loss)**\n",
    "    *  `tf.losses.mean_squared_error( labels= 실제값, predictions= 예측값 )`\n",
    "     <br><br>\n",
    "\n",
    "-  **loss를 최소화하는 방향으로 모델 훈련 (Adam Optimizer 사용)**\n",
    "    * `tf.train.AdamOptimizer( learning_rate ).minimize(loss)`    \n",
    "        - 학습률 (learning rate) : 경사하강 최적화 함수가 전체 손실이 감소되도록 가중치를 이동시킬 때, 얼마나 빨리 이동할지를 제어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화\n",
    "loss = tf.losses.mean_squared_error(labels = Y_true, predictions = Y_pred)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"blue\"> batch 그림추가 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실행\n",
    "* **세션 생성**\n",
    "    *  `with tf.Session() as sess:`<br><br>\n",
    "* **변수 초기화 실행**\n",
    "    * `sess.run( tf.global_variables_initializer() )` <br><br>\n",
    "\n",
    "* **반복학습 설정 (epoch, batch)**\n",
    "    - **지정한 training_epoch을 모두 수행해야 학습이 최종 완료**\n",
    "        <br> `for epoch in range(training_epochs):` <br><br>\n",
    "    - **total_batch가 모두 수행되어야 epoch 1번을 수행한 것임**\n",
    "         <br>    `for i in range(total_batch):`<br><br>\n",
    "    \n",
    "    - **batch_size에 따라 total_batch 개수가 결정됨**\n",
    "        - `total_batch = int(len(train_x_mlp) / batch_size)`\n",
    "        - batch_size : batch 1번에 사용할 데이터의 양\n",
    "        - 전체 데이터 10개 / 배치 사이즈 2개 = 배치가 5번 돌아야 epoch 1 수행 <br><br>   \n",
    "        \n",
    "    - **batch_size만큼 데이터 슬라이싱**\n",
    "        - `batch_x, batch_y = train_x_mlp[start:end], train_y_mlp[start:end]`<br><br>\n",
    "\n",
    "* **모델 학습**\n",
    "    * `sess.run([loss, train_op], feed_dict={X: batch_x, Y_true: batch_y})`\n",
    "    * **.run( )에 수행하려는 연산을 입력 *\n",
    "        * 학습은 loss의 최적화 과정이 이루어 지는 것을 의미하기 때문에 train_op를 입력\n",
    "        * loss도 값 확인을 위해 실행\n",
    "        \n",
    "    * **feed_dict 사용하여 배치 사이즈만큼의 입력 데이터 지정**\n",
    "        - 딕셔너리 형태로 제공\n",
    "        - feed_dict={플레이스홀더 변수 이름 : 값의 이름}<br><br>\n",
    "\n",
    "* **모델 평가** \n",
    "    - **loss값이 줄어드는 것으로 학습 정도를 확인**\n",
    "    - **테스트 데이터를 입력값으로 제공하여 예측값과 실제값(test_y_mlp)을 비교**\n",
    "    - `예측값 = sess.run(Y_pred, feed_dict={X: test_x_mlp}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"blue\"> batch 셔플 문의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "# 트레이닝 실행\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_loss = 0 # 초기값\n",
    "        total_batch = int(len(train_x_mlp) / batch_size)\n",
    "# 배치 셔플\n",
    "        for i in range(total_batch):\n",
    "            start = i * batch_size\n",
    "            end = min(i*batch_size + batch_size, len(train_x_mlp))\n",
    "            batch_x, batch_y = train_x_mlp[start:end], train_y_mlp[start:end]\n",
    "            c, _ = sess.run([loss, train_op], feed_dict={X: batch_x, Y_true: batch_y})\n",
    "            avg_loss += c / total_batch\n",
    "\n",
    "        print('Epoch:', '%03d' % (epoch + 1), 'loss =', '{:.9f}'.format(avg_loss))\n",
    "\n",
    "    print('----- Learning Finished! -----')\n",
    "    \n",
    "\n",
    "    # 모델 평가 (예측) \n",
    "    print(\"Prediction: \", sess.run(Y_pred, feed_dict={X: test_x_mlp[:1]}))\n",
    "    print(\"True Label: \", test_y_mlp[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/mlp_tf/mlp_concept.png\" width=700 height=800 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------\n",
    "*End of Document*"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Tensorflow Python3.6 (conda env)",
   "language": "python",
   "name": "tf-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
